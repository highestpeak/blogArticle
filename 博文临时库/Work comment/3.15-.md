# 3.15

问题

- 云盘中的文件是否需要被搜索到？

- 需不需要按类型，每种类型进行抽样，根据每种类型算权重和分数段

  表格和文档的处理也不应当相同？因为表格会有很多重复项（每列的值是有限的），但是我这里处理这个内容有必要么？

- 1w条数据只是2020-9-1到2020-9-3的，可能不满足全局分布

  =====>

  

统计

- 为什么不直接通过数据库访问这些数据？

- 处理

  - 处理空格

  - 只有一个url

  - 没有内容

  - 字符串长度等于1的(内容为`\u0003\u2028`)

  - [有的文档经过字符串的strip等的处理后就会是很短的（例如`fcAAG9duVlNl7pB4z88mMD0HF`）](https://docs.corp.kuaishou.com/d/home/fcAAG9duVlNl7pB4z88mMD0HF)

  - 字数计算不算少，但是好像没什么价值的：<u>***如何处理***</u>

    - https://docs.corp.kuaishou.com/d/home/fcABZWZd23neDlIqmcgmV8kj3 这就两百个字？

      https://docs.corp.kuaishou.com/d/home/fcACWKN7V_xO7CuRjH4N8vdTP

      https://docs.corp.kuaishou.com/d/home/fcAB6NKIA7PaJofToeim91YoV

    - 所以应该去掉图片的占位符的长度？但占位符也差不了几个字。一个图也就四五个字符长度？

  - 非正常数据，貌似是测试数据：**<u>*这种文档只有几个，分数异常也没有关系？*</u>**

    - https://docs.corp.kuaishou.com/d/home/fcACIExdSny3pZZCYJVMM1bVd 
    - https://docs.corp.kuaishou.com/d/home/fcACxRjD1a6nDJMCfhMLJZyxd 

  - 因为要看总的数目分布，所以应该用cumsum函数

    重要的文档总是少的？所以观察此图，在1500字之前的可能相对都不太重要（查看了一些文档，只要是有点用的好像都至少上千字）

    ![image-20210315145944407](/Users/highestpeak/Library/Application Support/typora-user-images/image-20210315145944407.png)

    此图为累积求和，根据增长速度，表明之后文档增加的数量，

    ![image-20210315150213414](/Users/highestpeak/Library/Application Support/typora-user-images/image-20210315150213414.png)

    重要文档占总文档的比例为多少，然后在此选取一个值，如果占1/3则可以选取2000字?但这样是不是会漏掉某些在2k字之下但是也重要的

    ![image-20210315150805539](/Users/highestpeak/Library/Application Support/typora-user-images/image-20210315150805539.png)

    如果要筛掉10%或者剩下10%？则在这里选取一个值

  - 使用`likecountDf.cumsum().plot()`类似的在图中选取一个点，点左右即为相应分布状况。不用 cumsum 好像毫无作用

    cumsum最终必定渐进3600等，因为总数就是那些，所以要放大，向左寻找合适位置进而分割对应的比例

  - 所以按照过滤掉2/3的文档来说，每个值的大致选取: **<u>*下面的情况说明该1w条数据不能找出一个合适的公式*</u>** 

    - Word count: 2000字
    - collect 和 quick 和 notificationUserSubscribe ：没有参照（因为样本没有数据）
    - Likecount: 大于1 (一方面不能给予太大的分数，另一方面其他时间段的文档是不是分布有所不同)
    - Share count: 大于1
    - discussionCount：大于1
    - view count: 大于20
    - viewpersoncountDf: 大于4
    - 按照对数函数拟合

  - 处理权重分组：(word count)     (like share discussion count viewperson count)   (View count 和 viewperson count)

    - word count：

    - Like count: 

      通过分析所有数据（<u>*能sql查询白浪费时间抽样一万条*</u>）

      ```
      select likes from
          (select count(id) likes from cosmo_like group by cosmo_id) as likes_table
      group by likes;
      
      select count(*) likes_count,likes from
          (select count(id) likes from cosmo_like group by cosmo_id) as likes_table
      group by likes;
      ```

      折线图选取的分段 Likes: 0个 0分、1个5分、2个3个10分、4-7个55分、8-11个 85分、15-30个 95分、30-之后 100分

      （根据斜率的比值？整体的分布）

      <u>***（这样算出来的数据是有时效的，比如公司扩大了，人员变更了，缩小了，都需要改这个值）***</u>

      **<u>*（并且算的方法也可能要写明，除非最后把这个评分标准给变了）*</u>**

    - collects 和 discussion 和 like 和 share 和 view_person_times 和 view_times 都按照 likes这样来算

    - 总分，比如

      - 参考分有价值，word count也有价值，则提升分数 ，最高分 100

      - ~~（潜力）word count 有价值，参考分没有价值，则正常分数，最高分 80分 参考分乘0.8~~
        - **<u>*根据潜力的不同也可以来继续划分（比如创建时间越早，越没有share count 那么潜力分就越低，但这个怎么划定呢？）*</u>**
      - ~~参考分有价值，word count 没有价值，则降低分数，最高分 50分~~

      - 都没价值就没分，最高分 0

    - **<u>*单纯根据word count计算没有意义感觉，只能过滤掉明显字数少的（单纯url的、。。等上面的情况）,例如测试文档可能在各个字数段都有，虽然可能只有几个异常值？*</u>**

      关键是 word count 的分数：只能简单判断有误价值，按照长度的分布来区分分数是无意义的

    - 各个参考分项之间的权重  (like share discussion count viewperson count)  >  (View count 和 viewperson count)

      - 也可以通过数据库来分析出来



- kconf 设定一个标记，每次更新必须更新这个标记，然后重新“编译”公式
- 相应的评分计算公式用kconf写，java项目里有一个方法/类来parse这个公式到代码，然后对每个doc应用这段代码
- 其实这个过程：查数据库--->下载各个csv--->找区间--->更改kconf值也都可以用代码写出来（如果评分逻辑不变的话）



Quicks \ notificationUserSubscribe区分度不大，则没有设置，类似只有如下几种情况，区分度不大

![image-20210315173436416](/Users/highestpeak/Library/Application Support/typora-user-images/image-20210315173436416.png)

# 3.16

1. --15:40试图寻找评分方式
2. 在内容同步的地方洗掉 只有一个链接的情况
3. 在搜索过程中加上没有参照的评分依据



注

对于单个文档的不同表之间的触发更新请求，通过 esIndex_cosmoId 作为唯一键值，在延迟队列中去重，减少不必要的更新操作；



级联更新

1. 文件夹添加快捷方式等操作发生时，可能导致包含的子文档的父路径发生增加，但是不会有数据记录的增加，对应类型的 shortcut 记录发生变动时，会触发所以子文档的级联更新。
2. 级联更新会延迟 30s，也会参与 esIndex_cosmoId 的去重。

# 3.17

- wordContentConsumer ==> EsContentUpdateTaskService:checkCosmoContentWithCosmoId

  在此处判断内容是否需要更改(cosmo type + content test)

  - 在这里获取 spacers 判断内容？

    但是这样就不能在WordEsIndexServiceImpl中获取spacer来作为内容

    （不如再加一个service？）(或者在这里触发update然后update判断是否为这种更改？不太行吧，还有其他的实时更新的用这个，增加代价)

  - 在这里接口加一个方法，有一个抛出异常的默认实现，然后word实现，**触发内容更改就用这个**

    注意也要把评论写进去

- ==>WordEsIndexServiceImpl

  - 需要知道内容是否是 去除链接等的更改，进而在 msg 里加一个标记

    （如果去除链接后还有值，那么就不需要标记，否则就需要，因为content为空不触发更改？）

  - 所以需要改 esIndexService 接口？



- ==> EsUpdaterListener 判断 msg 的标记==>加到队列中
- ==>CosmoEsUpdateService 执行 update
  - 如果要传递标记那么就应该修改 DocsEsUpdater.EsUpdateRequest 以加上标记
  - mergeTwoRequest 这里也需要判断内容
- ==> CosmoDocHelper: toUpInsertXContentBuilder
  - 如果要在这里判断，那么就需要 DocCosmoAll 也改动
  - 333 content blank 判断



- EsUpdaterListener 是不是有一个问题：不能把全文从有内容到无内容进行清除？可以，数据库不一样





- 加一个update触发

  不用新建索引，但是需要改内容，

- update方法判断内容

- 加一个标记

  （如果去除链接后还有值，那么就不需要标记，否则就需要，因为content为空不触发更改？）



- 一个一次性的task跑一遍去掉link
- EsUpdaterListener 这里判断content
  - 现在/以后有无只有一个链接的情况
- 或者WordEsIndexServiceImpl这里判断content去掉link
- 去掉link并且如果去掉后内容为空，则无必要再加一个标记，直接就不写content了



- 去掉 blank 判断，全都加一个 content 字段，但是这样的话那些binlog的触发更新?
- 



# 3.18

- 如果用正则，则匹配url但是如果url之后紧跟其他url合法字符，那么也会被删掉，

  - 使用固定的url匹配模式

    https://wiki.corp.kuaishou.com/pages/viewpage.action?pageId=601632495 例如该url最后 page id 只匹配几个数字，然后去掉这一部分

  - 从 伏特加 doc 里获取链接格式的截止位置，从而去掉这个链接

- 现在是如果出现源链接，则去掉首行

- 编写去除首行 ”源链接“ 的代码

# 3.19

- listener source null
  - 有位置并未设置 source 而 protobuf 生成的代码对msg为空字段抛异常
  - （为什么有文件夹类型的、群组类型的cosmo传过来，binlog导致的？那就是没有启动binlogconsumer新版的问题）设置了一个
- 未重新设置 cosmoAllTask 的offset，以为不是stagging环境的
- 未重启三个consumer，导致listener不断抛异常

![image-20210319213617001](/Users/highestpeak/Library/Application Support/typora-user-images/image-20210319213617001.png)

- ```
  com.google.common.util.concurrent.UncheckedExecutionException: UninitializedException(resultCode=DOC_UNINITIALIZED, docId=fcADHv8i2gp7AJG-4f
  bINSGIF)
  ```

# 3.21

- 去重排队、线程队列
- es评分计算



- V1 v2 cluster ？
- WordEsIndexServiceImpl 的 UncheckedExecutionException 不允许 未初始化 文档 调用get 



- 看了搜索流程，找一下从哪里加字段、在哪里进行精排



# 3.22

```
"should": [
...
        {
          "bool": {
            "must": [
              {
                "exists": {
                  "field": "content_length"
                }
              }
            ],
            "should": [
              {
                "range": {
                  "content_length": {
                    "gt": 0,
                    "boost": 10
                  }
                }
              }
            ]
          }
        }
...
]
```



- 找3个异常数据的原因？
- 添加content_length字段
- 

# 3.23

```
GET is_docs_join_new/_search
{
  "from": 0,
  "size": 10,
  "query": {
    "boosting": {
      "positive": {
        "bool": {
          "filter": [
            {
              "terms": {
                "id": [
                  "fcADL7JQbyzz7rgfraHTPkRhc",
                  "fcAAvaLKJO8cS8sfTKSYOPknf",
                  "fcAD6jDym2DOhpp0KyJ0XG7Zx",
                  "fcABRORT45zMPRWI2QJjmYywJ",
                  "fcADrBAk2NhLVLivQ6sacYDbA",
                  "fcAA8By5jqSEjoX32cGX3DgUN"
                ],
                "boost": 1
              }
            }
          ],
          "should": [
            {
              "function_score": {
                "query": {
                  "match_all": {}
                },
                "functions": [
                  {
                    "weight": 10
                  }
                ]
              }
            }
          ]
        }
      },
      "negative": {
        "bool": {
          "filter": {
            "exists": {
              "field": "content_length"
            }
          },
          "must": {
            "term": {
              "content_length": {
                "value": 0
              }
            }
          }
        }
      },
      "negative_boost": 0.5
    }
  },
  "_source": {
    "includes": [
      "id",
      "content_length",
      "content"
    ],
    "excludes": []
  }
}

```

- es 搜索 加了 len 字段，用 boosting 查询
  - 使用 kconf 配置 boost，boost 为 1则不降权，否则降权
- statistics 加了新的统计字段但是还没有用



# 3.24

- 0值有意义，设为-1值
- protobuf脏数据
- 日志调试和窗口debug调试



- 搜索过程中content_length为0降权,取出es的content_length字段,精排评分加字段,BinlogListener的cosmo表insert事件触发es的内容和内容长度字段创建
  - boosting查询调整
- 

# 3.25

- 看了 hive 几个表的建表语句，学习了下建表用法

# 3.26

- ```
  grep "es finish bulkUpdateOrInsert status:OK, esCluster:v1" console-json.log.2021-03-25.1 | tail -100 > /tmp100.txt
  cat /tmp100.txt | awk -F "cosmoId:" '{print $2}' | awk -F "," '{print $1}'
  ```


# 3.29

- context 没有释放可能导致异常？？？

# 3.30

- 建立了四个hive表，倒入数据

# 3.31

- 反例表

# 4.1

- 需要找到存储 文档相关联链接的 存储格式

  然后在实补偿的时候 wordEsIndexservice 去 伏特加 里找，计数然后写入es（要不还是写入所有的关联id？因为谁知道哪一天再用到这个id呢？）

- 实时的时候，需要在文档被更新的时候，向数据库写入

  需要找到文档被更新的时机的地方

# 4.8

- 