# 4.12

- 搜索删除 bug 后端代码提交 
- reference 抽取代码提交

        "https://docs.corp.kuaishou.com",
      	"https://docs.qingque.cn",
      	"https://is-docs-stage.corp.kuaishou.com",
      	"https://docs-pre.qingque.cn/"


        "https://docs.test.gifshow.com",
      	"https://is-docs-test.corp.kuaishou.com/"
# 4.13

- 调研近义词？

  https://github.com/fighting41love/funNLP

  ???

# 4.14

- 待做：

  - ik代码里分词
  - es会把查询语句explain，进行分词，然后组合成一个复杂的查询，然后逐个去查询，现在直接组合最后一步查询，直接去查

  原来：java es request -> es -> es explain and 分词 -> es final query -> return result

  现在：java 分词 -> es final query -> return result

- 写/抄了一个定时拉取，一个没有运行过的逻辑。。。



在低峰期上线sql，修改表结构



explain: true

profile: true

# 4.15

- 需要开AB，不要全部都用上近义词
- 需要近义词的组合，所有的近义词都要查



1. 当更新的时候不让搜索流程调用近义词，不再做近义词查询

   尽管如此，也需要一个map存上一次加入词典的数据，这一次要把没有的去掉

2. 要么就改他的代码

3. [要么就反射，反射的话，内部对象的地址是否一样？](https://juejin.cn/post/6844903679602982919) 注意static

   https://stackoverflow.com/questions/20786961/how-to-create-multiple-instances-for-singleton-class

4. 想一个近义词的查询如何去做，如何向es发请求，一个一个发太多了，需要优化

   中文有没有把一个词扩展成多个词的情况...貌似无

   直接扩展一个查询关键字，将近义词直接加上去，然后对近义词添加negative降权。例如：查询 aaa bbb ccc 其中 aaa 的近义词是 AAA BBB的查询是BBB，那么就查询 aaa,AAA bbb,BBB ccc然后在negative里添加AAA、BBB降权。.......不降权，进行权重提升，只不过提升值不一样，一个提升5一个提升10这个样子

   - 这样本可以使用es直接进行近义词组合，但是这样的话，es就会把所有的近义词都加上，效率降低

   - 直接写一堆should，提升值不一样

     **<u>*为了避免被再次分词*</u>**，~~使用query string？？query string是干什么的？~~

     ~~避免被再次分词~~--->~~短语搜索 match_phrase~~

     `match_phrase` 查询首先将查询字符串解析成一个词项列表，然后对这些词项进行搜索，但只保留那些包含 *全部* 搜索词项，且 *位置* 与搜索词项相同的文档

   explain 查询近义词过程 Es 的近义词查询是如何进行的？查询阶段的分词如何进行的？

   - [todo：查看 简单收缩、简单扩展、类型扩展在es中执行的explain](https://www.elastic.co/guide/cn/elasticsearch/guide/current/synonyms-expand-or-contract.html)  直接全都塞进去

   ~~todo：queryString查询是如何做的~~ queryString 是变相bool查询，也会分词

> ：

1. 更新词典时使用反射，创建新的词典实例，然后赋给原来的，只是需要注意是否map地址一样

   - 暂时只拉取一遍词典
   - <u>*Todo：之后修改他的源码*</u>

2. 近义词：

   先进行所有组合（取前几个关联性高的组合？）

   构建近义词查询query，即把分词结果用term和should匹配

在本地先跑一下

> 上线reference，做搜索近义词分词（需要加载远程分词词典、近义词词典，分词词典需要改源码，否则有并发问题）
>
> 近义词处理后的怎么发到es出处理
>
> 先写一个全字符串拼接的发到es去处理

# 4.16

- 先弄初始化的时候装配一次分词词典，其他时候不定时拉取

  - ~~[pom里弄一个exclude，把lucene的多余版本去除，只用es的版本](https://blog.csdn.net/eff666/article/details/51991465)~~

- 然后近义词词典---->放到kconf上

- 然后弄近义词逻辑

  所有近义词的组合，每个一个字符串，构建一堆should

- 然后弄一下AB



ik分词算法的 ik_smart分词过程？

内部原始词典针对 “分级分离规则案例 极速版定制” 分词

```
[分级分离_CN_WORD, 规则_CN_WORD, 案例_CN_WORD, 极速_CN_WORD, 版_CN_CHAR, 定制_CN_WORD]
```

添加新词 “分级分离规则” 后分词

```
[分级分离规则_CN_WORD, 案例_CN_WORD, 极速_CN_WORD, 版_CN_CHAR, 定制_CN_WORD]
```

添加新词 “分级分离规则” 和“规则案例” 后分词

```
[分级分离_CN_WORD, 规则案例_CN_WORD, 极速_CN_WORD, 版_CN_CHAR, 定制_CN_WORD]
```

?????

# 4.18

- 近义词逻辑，尚未测试

- 近义词AB，代码逻辑，但尚未测试也尚未添加kconf

- ~~Todo: 近义词词典放哪里？~~

- ~~先构造一个近义词词典，看看有多大，是否能放到kconf里，甚至来说，是否能放到内存里~~

  - ~~相同的词语，可能有不同的词意，如大家，有大伙儿、大学者、大家族的意思，这怎么处理？？？~~

    ~~全部替换~~

- ```
  zjk-comment: ik的内置主词典大概是2M，所以扩展词典和近义词词典大概也是2M+2M,
   当更新词典时会有冗余数据，旧词典和新词典并列存在，并且还有一份response内容，也就是(2M+2M+2M)*3=18M
   如果频繁更新，是否会出现旧词典堆积，没有被即时回收
   
  zjk-comment: 即使写一个进行delWords的,因为ik的segment中的char是相互依赖的，不知道有没有其他segment在用
   所以不能简单删除char，即不能删除words，但可以disable
  
  zjk-comment: 近义词有很多怎么处理
  
  genMiniShouldOneList
  zjk-comment: AB分组配置、scoreWeight配置、
  ```

# 4.19

- 测试
- hive表加字段
- 使用编辑距离：不太行感觉，因为编辑距离的话就会只选用那些只替换了一个词的了？如果按照char而不是词的距离可能还行，