海量数据问题一般来说不能够一次性的把数据从头到尾解决掉，因为数据太大了，我们必须把它划分成小问题。

这样的海量数据问题例如：

- 海量日志数据，提取出某日访问站点次数最多的IP
- 在十万的数字中找出前100？
  - 10亿的数字找前10万，空间给1亿？
  - 100亿数字找前10亿，空间1亿？
- 给定a、b两个文件，各存放50亿个URL，每个URL占64字节，内存限制是4G，找出a、b文件共同的URL
- 十几万条已排好的数据在redis里，新来一条数据，怎么快速更新排行榜（？不清楚）
  - 分桶排？ 0~10w， 10w~25w， 25w~30w，... ,50w~100w ,各一个桶？
- top K问题
- 海量数据分布在100台计算机中，高效统计出数据的TOP10
  - 如果每个数据元素只出现一次，而且只出现在某一台计算机中，怎么算
  - 如果同一个元素重复出现在不同的计算机中呢
- 在海量数据中找出重复次数最多的一个

解决海量数据问题有几个通用的步骤：

- 分解大问题，解决小问题，从局部最优中选择全局最优
- 分解过程常用方法为散列函数：hash(x)%m。m为小问题的数目，比如把一个大文件分解为1000份，m=1000；
- 解决小问题辅助数据结构：hash_map，Trie树，bit map，二叉排序树（AVL，SBT，红黑树）；
  - 采用hash_map来进行频率统计
  - 堆排序、快速排序得到最多最少的元素，优先队列得到小问题的top k元素，
  - 对每个小问题排序，然后对整个问题归并排序
- top K问题：最大K个用最小堆，最小K个用最大堆

解决海量数据问题有的几个通用方法：

1. 分而治之/hash映射 + hash统计 + 堆/快速/归并排序
2. 双层桶划分
3. （布隆过滤器）Bloom filter/Bitmap
4. Trie树/数据库/倒排索引
5. 外排序
6. 分布式处理之Hadoop/MapReduce





分而治之/hash映射 + hash统计 + 堆/快速/归并排序：

1. 散列函数取模，把大文件分成小文件
2. HashMap计数进行频率统计
3. 进行堆排序或者快速排序找到最多的，快速排序的划分可以找到第n大的数

对于第一点的解释：

Hash取模是一种等价映射，不会存在同一个元素分散到不同小文件中的情况，相同的IP在hash取模后，只可能落在同一个文件中，不可能被分散的。因为如果两个IP相等，那么经过Hash(IP)之后的哈希值是相同的，将此哈希值取模，必定仍然相等

适用问题：

- 海量日志数据，提取出某日访问站点次数最多的IP
- 给定a、b两个文件，各存放50亿个URL，每个URL占64字节，内存限制是4G，找出a、b文件共同的URL
  - 找出a、b散列后的每个小文件的共同URL，注意：a、b都对一个共同的数取模得到相同数量的小文件
- 在十万的数字中找出前100（Top K）
- 海量数据分布在100台计算机中，高效统计出数据的TOP10
  - 在每台计算机上求出TOP10，然后把所有的TOP10组合起来，求出总共的TOP10。如果是有重复元素，则每次计算TOP10时要考虑元素的数目，记录元素出现次数，最终汇总时需要对出现次数求和



双层桶划分：

（元素的范围很大，而不是元素的数目很多？）

适用问题：

- 2.5亿个整数中找出不重复的整数的个数

  整数个数为2^32个，划分成2^8个区域，将数据分离到不同的区域，然后不同的区域利用bitmap？

- 5亿个int找它们的中位数

  - 和上面的问题一样使用bitmap

  - 中位数一定是第2.5亿个，基于快速排序划分的想法，可以不用排序就找到第N大的数：

    按照每个int的二进制位进行分桶（每个桶其实是一个文件），例如我们根据int高位的前N位，则我们可以划分成2^N个桶，根据前N位将每个整数放到对应的桶

    在上面这个过程结束后，我们可以知道每个桶的数目，由于桶的高位前缀我们知道所以我们可以知道中位数落在了哪一个桶，然后我们就可以对这个桶快速排序或者内存不够的话就再次依据次高位进行划分

    - 例如分成4个桶（下面为高位前缀）：00、01、10、11，每个桶数目分别为：1亿、0.5亿、1亿、2.5亿，那么中位数必定在第三个桶



（布隆过滤器）Bloom filter/Bitmap：

- 可能会有错误情况
- 判断存在是可能存在，不存在是必定不存在
- 传统布隆过滤器不支持删除。但是名为 Counting Bloom filter 的变种可以用来测试元素计数个数是否绝对小于某个阈值，它支持元素删除。

布隆过滤器是一个 bit 数组：

![](E:\_data\博文临时库\博文中的图片\布隆过滤器.jpg)

要映射一个值到布隆过滤器中，我们需要使用**多个不同的哈希函数**生成**多个哈希值，**并对每个生成的哈希值指向的 bit 位置 1，例如针对值 `baidu` 和三个不同的哈希函数分别生成了哈希值 1、4、7，则上图转变为：

![](E:\_data\博文临时库\博文中的图片\布隆过滤器插入示意1.jpg)

再存一个值 `tencent`，如果哈希函数返回 3、4、8 的话，图继续变为：

![](E:\_data\博文临时库\博文中的图片\布隆过滤器插入示意2.jpg)

如果想查询 “`dianping`” 这个值是否存在，哈希函数返回了 1、5、8三个值，结果我们发现 5 这个 bit 位上的值为 0，**说明没有任何一个值映射到这个 bit 位上**，因此我们可以很确定地说 “`dianping`” 这个值不存在。而当我们需要查询 “`baidu`” 这个值是否存在的话，那么哈希函数必然会返回 1、4、7，然后我们检查发现这三个 bit 位上的值均为 1，那么我们可以说 “`baidu`” **存在了么？答案是不可以，只能是 “`baidu`” 这个值可能存在。**

https://zhuanlan.zhihu.com/p/43263751

适用问题：

- 给40亿个不重复的unsigned int的整数，没排过序的，然后再给一个数，如何**快速判断这个数是否在**那40亿个数**当中**？
- 常见就是判断一个数是否在大量的数当中
- 垃圾邮件过滤的黑白名单方法
- 爬虫(Crawler)的网址判重模块

布隆过滤器可以插入元素，但不可以删除已有元素。其中的元素越多，false positive rate(误报率)越大，但是false negative (漏报)是不可能的

在使用布隆过滤器的时候，如果想获得一个可接受的误报率，那么首先要选择合适的哈希函数，其次要协调好哈希函数数量和比特数组大小之间的关系。

为了保证运行效率，应该选择尽可能快的哈希函数，比如：murmurhash、FNV，至于 md5、sha1 等等，并不是好选择

如果使用很多很多的哈希函数，加上很大很大的比特数组，那么无疑可以把误报率降低到趋近于零，不过出于效率和成本的考虑，我们不会那样干，实际使用中，会通过调整哈希函数数量和比特数组大小之间的关系，来获得一个可接受的误报率，

布隆过滤器需要进一步学习？

https://blog.huoding.com/2020/06/22/825

https://www.cnblogs.com/sunsky303/p/11497370.html



1000 亿个无符号整数，找最大的 100 个。内存不够的情况下用什么方案？内存充足的情况下呢？ partion 的方案不稳定，有什么稳定的方法吗？