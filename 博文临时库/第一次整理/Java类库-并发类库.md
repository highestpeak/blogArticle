---

---

# 综述

并发，重要但困难的问题。他有着如此多的注意事项，以至于让人望而生畏。

提到并发，就会想到并行，从而我们也就需要注意并发和并行的区别和联系。

为什么会出现并发？并发问题是由什么造成的？答案就是线程和进程。那么相应的，如何在并发场景下对线程/进程进行一系列操作？线程的状态转换是由什么函数或者操作触发的？多线程下JAVA基础那些知识是否有了新的变化？这是我们需要学习记忆的，即**线程本身操作**的问题。也就是基础线程机制。

并发是为了获得多任务处理的能力，在这样的任务中难免会出现一系列的合作问题、竞争问题，我们也需要明白如何去解决以保证**线程安全**。

并发为了合作竞争、互斥同步的问题，同时也引入了其他问题，例如我们如何权衡并发带来的额外开销，这些开销很多时候可能比他带来的好处更多：线程创建开销、加锁开销、等待开销、上下文切换开销。我们需要何时的权衡来提高性能。

- 为了减少线程创建开销、上下文切换开销，提出了**线程池**
- 为了减少加锁开销，可以使用**CAS**或灵活选取合适的**锁类型**

如果说程序就是数据结构加算法，那么并发问题我觉得也可以说是**存储和操作**，也就是内存可见性和操作原子性的问题：存储问题是由于线程私有空间造成的，操作是由于不同线程进行操作造成的。

---

从这个类库我们也可以学习到一系列的**面向对象**的知识，以及一系列的**设计**策略，当你学习之后你会发现之前所写的程序大概都是面向过程的初学者代码。（但是，又不是不能用）

为了提高线程利用率，也就是减少线程创建开销，JAVA分离了线程和线程所作的工作，这就是Thread和Runnable（Callable），为了得到任务的结果又设计了Future。在这个地方其实就用到了回调也就是策略模式。

总之，我们也将学习到一系列的设计策略和权衡。

---

在学习并发的过程中会遇到一系列的词语和场景，他们是问题的进一步细化，一个完整图景的组成部分，`不可不察也`

- 堵塞、等待
- 饥饿、死锁、活锁

---

使用多线程的本质： 1. 利用多核。 2. 当I/O阻塞系统，但CPU空闲的时候，可以利用多线程使用CPU资源。

线程池本身就是一个天然的漏斗，可以缓冲一些系统处理不了的连接或请求。

- 线程堵塞意味着他不能去干别的事情，新的任务到达也不能使用这样的线程，造成的结果就是创建越来越多的线程
  - 线程占用较大内存，像Java的线程栈，一般至少分配512K～1M的空间，如果系统中的线程数过千，恐怕整个JVM的内存都会被吃掉一半。
  - 线程的创建和销毁成本很高，在Linux这样的操作系统中，线程本质上就是一个进程。创建和销毁都是重量级的系统函数。
- 线程的**切换成本很高**。操作系统发生线程切换的时候，需要保留线程的上下文，然后执行系统调用。如果线程数过高，可能执行线程切换的时间甚至会大于线程执行的时间，这时候带来的表现往往是系统load偏高、**CPU 使用率**特别高（超过20%以上)，导致系统几乎陷入不可用的状态。
- 容易造成锯齿状的系统负载。因为系统负载是用活动线程数或CPU核心数，**一旦线程数量高但外部网络环境不是很稳定，就很容易造成大量请求的结果同时返回**，激活大量阻塞线程从而使系统负载压力过大。





# 内存模型

Java 内存模型试图屏蔽各种硬件和操作系统的内存访问差异，以实现让 Java 程序在各种平台下都能达到一致的内存访问效果。Java的内存模型不同于计算机的内存模型，不能简单的一一对应起来。从一个这样的类比看：Java虚拟机是一个计算机，内存模型对应了计算机的内存模型，但是他们的各个部分不是一一对应的。

Java 内存模型包括主内存和工作内存两个部分。所有的变量都存储在主内存中，工作内存为线程所有，线程只能直接操作工作内存中的变量，不同线程之间的变量值传递需要通过主内存来完成。

- 这个工作内存不是一定对应计算机中的高速缓存，工作内存和主内存可以对应计算机物理结构中的内存、高速缓存、寄存器等位置
- 工作内存和主内存的划分和 Java 堆，栈，方法区的划分不同，两者基本没有关系，如果勉强对应，则主内存可理解为堆中实例数据部分，工作内存则对应栈中部分区域

**内存间交互操作：**

Java 内存模型定义了 8 个操作来完成主内存和工作内存的交互操作。

![](E:\_data\博文临时库\博文中的图片\Java内存模型.png)

- read：把一个变量的值从主内存传输到工作内存中
- load：在 read 之后执行，把 read 得到的值放入工作内存的变量副本中
- use：把工作内存中一个变量的值传递给执行引擎
- assign：把一个从执行引擎接收到的值赋给工作内存的变量
- store：把工作内存的一个变量的值传送到主内存中
- write：在 store 之后执行，把 store 得到的值放入主内存的变量中
- lock：作用于主内存的变量
- unlock



JMM关于synchronized的两条规定（synchronized如何实现内存可见性）：
（1）线程加锁时，将清空工作内存中共享变量的值，从而使用共享变量时需要从主内存中重新读取最新的值。
（2）线程解锁时，必须把共享变量的最新值刷新到主内存中。

## 内存模型的特性

有三大特性：原子性、可视性、有序性

**原子性：**

- 保障的是上面八个操作的原子性
- 可以使用一些方法来保障原子性：原子类（例如`AtomicInteger`）、synchronized

**可视性：**

- 可见性指当一个线程修改了共享变量的值，其它线程能够立即得知这个修改。Java 内存模型是通过在变量修改后将新值同步回主内存，在变量读取前从主内存刷新变量值来实现可见性的
- 主要有三种方法保障可视性：volatile、synchronized、final

**有序性：**

- 在一个线程观察另一个线程，所有操作都是无序的，无序是因为发生了指令重排序
- 保障有序性：volatile、synchronized

> 关于原子性的更多内容：

- 在有关Java线程的讨论中，一个经常不正确的知识是“原子操作不需要进行同步控制”。

  原子操作是不能被线程调度机制中断的操作；一旦操作开始，那么它一定可以在可能发生的“上下文切换”之前（切换到其他线程执行）执行完毕。**依赖于原子性是很棘手且很危险的**。

- 原子性可以应用于除long和 double之外的所有**基本类型之上的“简单操作”**。

  但是JVM可以将64位（long和 double变量）的读取和写入当作两个分离的32位操作来执行，这就产生了在一个读取和写入操作中间发生上下文切换，从而导致不同的任务可以看到不正确结果的可能性（这有时被称为**字撕裂**，因为你可能会看到部分被修改过的数值）。

  但是，当你定义long或 double变量时，如果使用 volatile关键字，就会获得（简单的赋值与返回操作的）原子性。

- Java中++和--不是原子性的，涉及到一个读操作和写操作

> 关于可视性的更多内容

- 相对于单处理器系统而言，**在多处理器系统上，可视性问题远比原子性问题多得多**。

  一个任务做出的修改，即使在不中断的意义上讲是原子性的，对其他任务也可能是不可视的（例如，**修改只是暂时性地存储在本地处理器的缓存中**）

- 另一方面，同步机制强制在处理器系统中，一个任务做出的修改必须在应用中是可视的。如果没有同步机制，那么修改时可视将无法确定。

- 应当和volatile关键字结合的来看待可视性问题

## 先行发生原则

除了有序性以外，JVM 还规定了先行发生原则，让一个操作无需控制就能先于另一个操作完成。主要有：

- 线程启动规则（Thread Start Rule）

  Thread 对象的 start() 方法调用先行发生于此线程的每一个动作

  ![](E:\_data\博文临时库\博文中的图片\Java内存模型-先行发生原则-线程启动原则.png)

- 单一线程原则（Single Thread rule）

  在一个线程内，在程序前面的操作先行发生于后面的操作

  ![](E:\_data\博文临时库\博文中的图片\Java内存模型-先行发生原则-单一线程原则.png)

- 线程中断规则（Thread Interruption Rule）

  对线程 interrupt() 方法的调用先行发生于被中断线程的代码检测到中断事件的发生，可以通过 interrupted() 方法检测到是否有中断发生。

- 线程Join 规则（Thread Join Rule）

  Thread 对象的结束先行发生于 join() 方法返回。

  ![](E:\_data\博文临时库\博文中的图片\Java内存模型-先行发生原则-线程Join原则.png)

- 管程锁定规则（Monitor Lock Rule）

  一个 unlock 操作先行发生于后面对同一个锁的 lock 操作。

  ![](E:\_data\博文临时库\博文中的图片\Java内存模型-先行发生原则-管程锁定原则.png)

- volatile 变量规则（Volatile Variable Rule）

  对一个 volatile 变量的写操作先行发生于后面对这个变量的读操作。

  ![](E:\_data\博文临时库\博文中的图片\Java内存模型-先行发生原则-volatile变量原则.png)

- 对象终结规则（Finalizer Rule）

  一个对象的初始化完成（构造函数执行结束）先行发生于它的 finalize() 方法的开始。

- 传递性（Transitivity）

  如果操作 A 先行发生于操作 B，操作 B 先行发生于操作 C，那么操作 A 先行发生于操作 C。

## volatile关键字

- 定义long或 double变量时，如果使用 volatile关键字，就会获得（简单的赋值与返回操作的）原子性，避免字撕裂

- **volatile关键字会导致相应的域向主存中刷新**，这确保了应用中的可视性。

  即便使用了本地缓存，情况也确实如此， volatile域会立即被写入到主存中，而读取操作就发生在主存中。

- **同步也会导致向主存中刷新**，因此如果一个域完全由 synchronized方法或语句块来防护，那就不必将其设置为是volatile的。

- 在非 volatile域上的原子操作不必刷新到主存中去，因此其他读取该域的任务也不必看到这个新值。如果多个任务在同时访问某个域，那么这个域就应该是 volatile，否则，这个域就应该只能经由同步来访问。

- 无法工作的情形：

  - 当一个域的值依赖于它之前的值时（例如递增一个计数器）， volatile就无法工作了。
  - 如果某个域的值受到其他域的值的限制，那么 volatile 也无法工作，例如 Range：类的lower和upper边界就必须遵循lower<=upper的限制。
  
- **Java 中能创建 volatile 数组吗？**

  能，Java 中可以创建 volatile 类型数组，不过只是一个指向数组的引用，而不是整个数组。意思是，如果改变引用指向的数组，将会受到 volatile 的保护，但是如果多个线程同时改变数组的元素，volatile 标示符就不能起到之前的保护作用了



volatile原理：

可视性原理：

1. 修改volatile变量时会强制将修改后的值刷新的主内存中。
2. 修改volatile变量后会导致其他线程工作内存中对应的变量值失效。因此，再读取该变量值的时候就需要重新从读取主内存中的值。

有序性原理：

happen-before规则+内存屏障

https://www.cnblogs.com/paddix/p/5428507.html



- 分配内存
- 初始化
- 变量指向这个分配的空间

> 一个例子

看下面一个例子，该程序将找到奇数值并终止。尽管 `return i`确实是原子性操作，但是缺少同步使得其数值可以在处于不稳定的中间状态时被读取。除此之外，由于`i`不是 volatile的，因此还存在可视性问题。

因此 `getValue`和 `evenIncrement`必须是 synchronized的。

``` java
public class AtomicityTest implements Runnable {
  private int i = 0;
  public int getValue() { return i; } // 注意这一句，不稳定的返回 注意:本句return是原子性操作
  private synchronized void evenIncrement() { i++; i++; }
  public void run() {
    while(true)
      evenIncrement();
  }
}
```

基本上，如果一个域可能会被多个任务同时访问，或者这些任务中至少有一个是写入任务，那么就应该将这个域设置为 volatile的。但是， volatile并不能对递增不是原子性操作这一事实产生影响。

如下所示。对基本类型的读取和赋值操作被认为是安全的原子性操作。但是，正如你在上面的`AtomicityTest `中看到的，当对象处于不稳定状态时，仍旧很有可能使用原子性操作来访问它们。

``` java
public class SerialNumberGenerator {
  private static volatile int serialNumber = 0;
  public static int nextSerialNumber() {
    return serialNumber++; // Not thread-safe 不是线程安全的
  }
} ///:~
```

# 线程安全

线程安全可以简单理解为一个方法或者一个实例可以在多线程环境中使用而不会出现问题。

为什么会存在线程安全性问题？简单的说就是由于多个线程访问了相同的资源。详细的说，Java中所有的线程都共享JVM进程的虚拟内存地址空间。一般的共享变量存放在共享区域（主内存）中。但是每个线程还有自己的本地缓存（工作内存），在线程读取变量时，会在其本地拷贝一份副本进行操作，这样就会导致共享内存（主内存）和本地副本（工作内存）存在不一致的情况。

首先说一下不是线程安全的常见情况：

- **static变量是线程不安全**
- **打印语句线程不安全**

那么如何创造一个线程安全的类、方法、变量呢？

线程安全的几种实现方式：

- 对象不可变：

  - final 关键字修饰的基本数据类型，final的应用使得整个类不可变
  - String
  - 枚举类型
  - Number 部分子类，如 Long 和 Double 等数值包装类型，`BigInteger` 和 `BigDecimal` 等大数据类型。但同为 Number 的原子类 `AtomicInteger` 和 `AtomicLong` 则是可变的
  - 集合类型，可以使用 `Collections.unmodifiableXXX()` 方法来获取一个不可变的集合

- 堵塞同步/互斥同步：

  synchronized 和 ReentrantLock，即加锁

- 非堵塞同步：

  CAS、原子类

- 无同步方案：

  - 无状态的方法：方法只使用局部变量，不依赖存储在堆上的数据和公用的系统资源、用到的状态量都由参数中传入、不调用非可重入的方法。
    - 如果一个方法不使用实例的任何成员变量（它仅使用局部变量和参数），那么他就是是无状态的，因此是线程安全的。
    - 调用它的代码可能不是线程安全的，但这是另一个讨论。例如，“日期不是线程安全的”，如果调用代码读取了另一个线程写入的日期，则必须在“日期”写入和读取代码中使用适当的同步
  - 线程本地存储ThreadLocal

> 关于上面实现方式的几个问题：

- 从互斥/堵塞的悲观看法 到 “先斩后奏”的乐天派：

  互斥同步最主要的问题就是线程阻塞和唤醒所带来的性能问题，因此这种同步也称为阻塞同步。

  互斥同步属于一种悲观的并发策略，总是认为只要不去做正确的同步措施，那就肯定会出现问题。无论共享数据是否真的会出现竞争，它都要进行加锁、用户态核心态转换、维护锁计数器和检查是否有被阻塞的线程需要唤醒等操作。

  （这里讨论的是概念模型，实际上虚拟机会优化掉很大一部分不必要的加锁，即通过逃逸分析）

  随着硬件指令集的发展，我们可以使用基于冲突检测的乐观并发策略：先进行操作，如果没有其它线程争用共享数据，那操作就成功了，否则采取补偿措施（不断地重试，直到成功为止）。这种乐观的并发策略的许多实现都不需要将线程阻塞，因此这种同步操作称为非阻塞同步。

- 忙等待堵塞和挂起堵塞：

  涉及到锁的释放和资源使用权的释放

  - **wait不是忙等待**
  - **调用wait会释放锁**
    - 而调用sleep、yield的时候锁并没有被释放

- 互斥下的交流：

  任务协作的关键是**互斥**，互斥的实现就需要任务之间的交流，Java给这种交流在Object类中提供了基础支持：**wait()和 notify()**，并发类库还提供了具有**await和 signal()**方法的**Condition**对象

- ThreadLocal：

  ThreadLocal是为了能够在当前线程中有属于自己的变量，不解决且不能解决同步问题、共享资源问题

> wait

wait接受亳秒数作为参数的版本含义与 sleep方法里参数的意思相同，都是指“在此期间暂停”。但是wait与sleep是不同的，对于wait而言，**wait与sleep的区别**如下：

1. 在wait期间对象锁是释放的。
2. 可以通过notify、 notifyAll，或者令时间到期，从wait中恢复执行。

> 复杂的衡量

锁或者说堵塞同步是为了首先保证数据的正确性，然后考虑操作的性能，这也是悲观锁和乐观锁的原因，如果都不正确那要他何用。（可能有一些正确性场景不是很高的地方，可能有一些一致性要求不是很高的地方）

阻塞或唤醒一个Java线程需要操作系统切换CPU状态来完成，这种**状态转换需要耗费处理器时间**。如果同步代码块中的内容过于简单，状态转换消耗的时间有可能比用户代码执行的时间还要长。在许多场景中，同步资源的锁定时间很短，为了这一小段时间去切换线程，**线程挂起和恢复现场的花费可能会让系统得不偿失**。

在选择线程安全的实现方式的时候，需要考虑很多方面，如：

- 该方法对于饥饿、死锁、活锁的处理和他们的出现概率。
- 协作带来的吞吐效率的影响。
- 线程切换开销
- 对于CPU时间的利用
- 可读性、可维护性上的诸多的问题

> 临界区的概念（synchronized和lock的临界区）

- 锁在大多数情况下不仅不存在多线程竞争，而且总是由同一线程多次获得，为了让线程获得锁的代价更低而引入了偏向锁
- 重量级锁要切换进程，切换用户态和内核态，开销大，因此使用CAS操作实现轻量级锁、
- 同样上一点相同，采用CAS实现的有一定CAS次数限制的自旋锁，适应性自旋锁则取消了次数限制
- 锁消除：
  - JVM检测到不可能存在共享数据竞争，则JVM会对这些锁进行锁消除。锁消除可以节省毫无意义的请求锁的时间。
  - 虽然程序员不会在明明知道不存在数据竞争的代码块前加上同步。虽然没有显示使用锁，但是在使用一些JDK的内置API时，如StringBuffer、Vector、HashTable等，这个时候会存在隐形的加锁操作。比如**StringBuffer的append()方法，Vector的add()方法**。
- 锁粗化：
  - 偏向锁==>轻量级锁==>重量级锁

虽然程序员不会在明明知道不存在数据竞争的代码块前加上同步。虽然没有显示使用锁，但是在使用一些JDK的内置API时，如StringBuffer、Vector、HashTable等，这个时候会存在隐形的加锁操作。比如**StringBuffer的append()方法，Vector的add()方法**。

## 算法原理

### CAS算法

CAS全称 Compare And Swap（比较与交换），是一种无锁算法。在不使用锁（没有线程被阻塞）的情况下实现多线程之间的变量同步。concurrent包中的原子类就是通过CAS实现的。（可以查看**并发实现机制-2-互斥实现**中的硬件互斥部分获得其他信息）

CAS算法涉及到三个操作数：

- 需要读写的内存值 V
- 进行比较的值 A
- 要写入的新值 B

当且仅当 V 的值等于 A 时，CAS通过原子方式用新值B来更新V的值（“比较+更新”整体是一个原子操作），否则不会执行任何操作。一般情况下，“更新”是一个**不断重试**的操作。

> CAS虽然很高效，但是它也存在三大问题

1. **ABA问题**

   CAS需要在操作值的时候检查内存值是否发生变化，没有发生变化才会更新内存值。**但是如果内存值原来是A，后来变成了B，然后又变成了A，那么CAS进行检查时会发现值没有发生变化，但是实际上是有变化的。**ABA问题的解决思路就是在变量前面添加版本号，每次变量更新的时候都把版本号加一，这样变化过程就从“A－B－A”变成了“1A－2B－3A”。

   - **JDK从1.5开始提供了`AtomicStampedReference`类来解决ABA问题**，具体操作封装在`compareAndSet()`中。`compareAndSet()`首先**检查当前引用和当前标志与预期引用和预期标志**是否相等，如果都相等，则以原子方式将引用值和标志的值设置为给定的更新值。

2. **循环时间长开销大**。CAS操作如果长时间不成功，会导致其**一直自旋**，给CPU带来非常大的开销。

3. **只能保证一个共享变量的原子操作**

   对一个共享变量执行操作时，CAS能够保证原子操作，但是对多个共享变量操作时，CAS是无法保证操作的原子性的。

   - **Java从1.5开始JDK提供了`AtomicReference`类来保证引用对象之间的原子性**，可以把**多个变量放在一个对象里来进行CAS操作**。

### AQS

AQS核心思想是，如果被请求的共享资源空闲，那么就将当前请求资源的线程设置为有效的工作线程，将共享资源设置为锁定状态；如果共享资源被占用，就需要一定的阻塞等待唤醒机制来保证锁分配。线程如果堵塞，则会被堵塞到一个队列中。

AQS可以实现独占锁和共享锁，实现方式就是对同步状态state附上不同的初始值：初始值state=0标识独占模式；初始值state=n表示共享模式，即n个线程共享。

- 这其实就是信号量的原理，非得整那么多花里胡哨的

基于这个state可以实现独占锁，共享锁；可重入锁和非可重入锁也可以实现。

# 具体编程

<u>*todo:没有整理好*</u>

## 原子类

这部分需要结合本文上面的CAS算法小节来了解。原子类是基于比较交换指令的，

原子类在常规编程很少会派上用场，但涉及性能调优时，他们就大有用武之地。 应该强调的是， Atomic类被设计用来构建 `java util. concurrent`中的类，因此只有在特殊情况下才在自己的代码中使用它们，即便使用了也需要确保不存在其他可能出现的问题。通常依赖于锁要更安全一些（要么是 synchronized关键字，要么是显式的Lock对象）

针对原子类以及jdk8的新的原子类，在另一篇文章中有介绍，读者可以去另一篇文章深入了解。<u>*todo: 在这里应当引用另一篇文章的链接*</u>

## 执行器Executor

executor只有一个execute方法

`ExecutorService`是启动任务的首选方法，`ExecutorService`将管理Thread对象，与命令设计模式一样（<u>*todo: ？？还没有体会到？？*</u>），他暴露了要执行的单一方法。 `ExecutorService`提供了一种将“任务提交”与“任务执行”分离开来的机制(解耦)。

``` java
public class CachedThreadPool {
    public static void main(String[] args){
        ExecutorService exec = Executors.newCachedThreadPool(); // 创建
        for(int i=0;i<5;i++);
        	exec.execute(new Liftoff); // 执行
        exec.shutdown();// 终止全部
    }
}
```

对shutdown的调用可以防止新任务被提交给这个executor，当前线程（本例main线程）将继续运行在shutdown被调用之前提交的所有任务，这个程序将在executor的所有任务完成之后尽快退出。

![](E:\_data\博文临时库\博文中的图片\drawio\Java并发类库-线程池.png)

# 良好实践

- 给线程起个有意义的名字，这样可以方便找 Bug。
- 缩小同步范围，从而减少锁争用。例如对于 synchronized，应该尽量使用同步块而不是同步方法。
- 多用同步工具少用 wait() 和 notify()。首先，`CountDownLatch`, `CyclicBarrier`, Semaphore 和 Exchanger 这些同步类简化了编码操作，而用 wait() 和 notify() 很难实现复杂控制流；其次，这些同步类是由最好的企业编写和维护，在后续的 JDK 中还会不断优化和完善。
- 使用 `BlockingQueue` 实现生产者消费者问题。
- 多用并发集合少用同步集合，例如应该使用 `ConcurrentHashMap` 而不是 `Hashtable`。
- 使用本地变量和不可变类来保证线程安全。
- 使用线程池而不是直接创建线程，这是因为创建线程代价很高，线程池可以有效地利用有限的线程来启动任务。

# 总结

- 存储问题是由于线程私有空间造成的，操作是由于不同线程进行造成的。

请不要简单的因为炫技或者偷懒而不加思考的使用原子类和利用原子性、可视性。

在向读者介绍这原子性和可视性两个问题和volatile时，可能有必要引述编程思想上这几句话，在本节结束时会再次重复以免读者忘记这一忠告。

> 如果你是一个并发专家，或者你得到了来自这样的专家的帮助，你才应该使用原子性来代替同步。如果你认为自己足够聪明可以应付这种玩火似的情况，那么请接受下面的测试：
>
> - 如果你可以编写用于现代微处理器的高性能JVM，那么就有资格去考虑是否可以进免同步
> - 这个测试的一个推论是：“如果某人表示线程机制很容易并且很简单，那么请确保这个人没有对你的项目做出重要的决策。如果这个人已经在这么做了，那么你就已经陷入麻烦之中了。”

# 参考

> 1. http://tutorials.jenkov.com/java-concurrency/java-memory-model.html
>
> 2. [CS-Note Java并发](https://github.com/CyC2018/CS-Notes/blob/master/notes/Java%20%E5%B9%B6%E5%8F%91.md)
>
> 3. [What Makes a Method Thread-safe? What are the rules?](https://stackoverflow.com/questions/9848067/what-makes-a-method-thread-safe-what-are-the-rules)
>
>    https://www.infoworld.com/article/2076747/design-for-thread-safety.html